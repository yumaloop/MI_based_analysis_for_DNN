{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Density Ratio Estimation for MI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper: http://proceedings.mlr.press/v4/suzuki08a/suzuki08a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pycuda.driver as cuda\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from models import DNN, CNN\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Info\n",
      "=========\n",
      "- use_cuda:  True\n",
      "- Path:  /home/uchiumi/JNNS2019/mnist_pytorch\n",
      "- PyTorch 1.0.1.post2\n",
      "- Python:  3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Setting Info\")\n",
    "print(\"=========\")\n",
    "print(\"- use_cuda: \", use_cuda)\n",
    "print(\"- Path: \", os.getcwd())\n",
    "print(\"- PyTorch\", torch.__version__)\n",
    "print(\"- Python: \", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model reload\n",
    "model = DNN()\n",
    "PRETRAINED_MODEL_PATH = \"/home/uchiumi/JNNS2019/mnist_pytorch/train_log/dnn_mnist__2019-0425-1923.pth\"\n",
    "model.load_state_dict(torch.load(PRETRAINED_MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf.) https://www.aiworkbox.com/lessons/examine-mnist-dataset-from-pytorch-torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = np.asarray(mnist_trainset[0][0]) # image\n",
    "y_train_0 = mnist_trainset[0][1] # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_loader_for_MINE = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_loader_for_MINE = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get layer values (the state of each nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_with_train_data(model):\n",
    "    model.eval()\n",
    "    list = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(train_loader_for_MINE):\n",
    "            result = model(data)\n",
    "            list.append(result)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_with_test_data(model):\n",
    "    model.eval()\n",
    "    list = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader_for_MINE):            \n",
    "            result = model(data)\n",
    "            list.append(result)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uchiumi/JNNS2019/mnist_pytorch/models.py:61: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(self.fc5(x))\n"
     ]
    }
   ],
   "source": [
    "list = get_nodes_with_train_data(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fc3_output', 'model_input', 'fc1_output', 'model_output', 'fc2_output', 'fc4_output'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_input torch.Size([1, 784])\n",
      "fc1_output torch.Size([1, 1024])\n",
      "fc2_output torch.Size([1, 512])\n",
      "fc3_output torch.Size([1, 256])\n",
      "fc4_output torch.Size([1, 128])\n",
      "model_output torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(\"model_input\", list[0][\"model_input\"].shape)\n",
    "print(\"fc1_output\",list[0][\"fc1_output\"].shape)\n",
    "print(\"fc2_output\",list[0][\"fc2_output\"].shape)\n",
    "print(\"fc3_output\",list[0][\"fc3_output\"].shape)\n",
    "print(\"fc4_output\",list[0][\"fc4_output\"].shape)\n",
    "print(\"model_output\",list[0][\"model_output\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = []\n",
    "fc1_output = []\n",
    "fc2_output = []\n",
    "fc3_output = []\n",
    "fc4_output = []\n",
    "model_output = []\n",
    "\n",
    "for i in range(len(train_loader_for_MINE)):\n",
    "    model_input.append(list[i][\"model_input\"].data.numpy().flatten())\n",
    "    fc1_output.append(list[i][\"fc1_output\"].data.numpy().flatten())\n",
    "    fc2_output.append(list[i][\"fc2_output\"].data.numpy().flatten())\n",
    "    fc3_output.append(list[i][\"fc3_output\"].data.numpy().flatten())\n",
    "    fc4_output.append(list[i][\"fc4_output\"].data.numpy().flatten())\n",
    "    model_output.append(list[i][\"model_output\"].data.numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = np.array(model_input)\n",
    "fc1_output = np.array(fc1_output)\n",
    "fc2_output = np.array(fc1_output)\n",
    "fc3_output = np.array(fc1_output)\n",
    "fc4_output = np.array(fc1_output)\n",
    "model_output = np.array(model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Density Ratio Estimation for MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model_input\n",
    "y = fc3_output\n",
    "z = np.concatenate([x, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 1024)\n",
      "(60000, 1808)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\underset{\\alpha \\in \\mathbb{R}^{b}}{\\rm maximize} \\, \\sum_{i=1}^{n} \\log \\left( {\\alpha}^{\\mathrm{T}} \\phi(z_i) \\right) \\\\\n",
    "    s.t. \\, \\frac{1}{n(n-1)} \\sum_{(i, j)} {\\alpha}^{\\mathrm{T}} \\phi(z_i) = 1, \\, \\alpha \\geq 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\alpha \\in \\mathbb{R}^{b}, \\, \\phi() \\in \\mathbb{R}^{b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\phi(z_i) = \\left( \\begin{array}{c} \\phi_1(z_i) \\\\ \\phi_2(z_i) \\\\ \\vdots \\\\ \\phi_b(z_i) \\end{array} \\right)\n",
    "    = \\left( \\begin{array}{c} k(z_i, c_1) \\\\ k(z_i, c_2) \\\\ \\vdots \\\\ k(z_i, c_b) \\end{array} \\right)\n",
    "    = \\left( \\begin{array}{c} \\exp\\left( - \\frac{{|| z_i - c_1||}^{2}}{2 \\sigma^2} \\right) \\\\ \\exp\\left( - \\frac{{|| z_i - c_2||}^{2}}{2 \\sigma^2} \\right) \\\\ \\vdots \\\\ \\exp\\left( - \\frac{{|| z_i - c_b||}^{2}}{2 \\sigma^2} \\right) \\end{array} \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\frac{\\partial L(\\alpha)}{\\partial \\alpha} = \\left( \\begin{array}{c} \\sum_{i=1}^{n} \\frac{\\phi_{1}(z_i)}{\\alpha} \\\\ \\end{array} \\left)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFkernel():\n",
    "    def __init__(self, sigma=0.5):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        numerator = -1 * np.sum((x - y)**2)\n",
    "        denominator = 2 * (self.sigma**2)\n",
    "        return np.exp(numerator / denominator)\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.sigma\n",
    "    \n",
    "    def set_params(self, sigma):\n",
    "        self.sigma = sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Density Ratio Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensityRatioEstimation():\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y \n",
    "        self.z = np.concatenate([x, y], axis=1)\n",
    "        self.n = x.shape[0]\n",
    "        \n",
    "    def loss(self, alpha, n):\n",
    "        for i in range(n):\n",
    "            np.dot(alpha, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRegression():\n",
    "    def __init__(self, kernel):\n",
    "        self.kernel = kernel\n",
    "        \n",
    "    def fit_kernel(self, X, y, lr=0.01, nb_epoch=1000, log_freq=50):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n = X.shape[0] # sample size\n",
    "        self.alpha = np.full(self.n, 1) # param alpha: initialize\n",
    "        self.gram_matrix = np.zeros((self.n, self.n))\n",
    "        \n",
    "        # Gradient Descent Algorithm to optimize alpha\n",
    "        for epoch in range(nb_epoch):\n",
    "            \n",
    "            # Gram Matrix\n",
    "            for i in range(self.n):\n",
    "                for j in range(self.n):\n",
    "                    self.gram_matrix[i][j] = self.kernel(self.X[i], self.X[j])\n",
    "                    self.loss, self.loss_grad = self.mse(self.X, self.y, self.alpha, self.gram_matrix)\n",
    "                    self.alpha = self.alpha - lr * self.loss_grad\n",
    "                    \n",
    "            if epoch % log_freq == 0:\n",
    "                print(\"epoch: {} \\t MSE of sample data: {:.4f}\".format(epoch, self.loss))\n",
    "                        \n",
    "                        \n",
    "    def mse(self, X, y, alpha, gram_matrix):\n",
    "        loss = np.dot((y - np.dot(gram_matrix, alpha)), (y - np.dot(gram_matrix, alpha)))\n",
    "        loss_grad = -2 * np.dot(gram_matrix.T, (y - np.dot(gram_matrix, alpha)))\n",
    "        return loss, loss_grad\n",
    "    \n",
    "    def predict(self, X_new):\n",
    "        n_new = X_new.shape[0]\n",
    "        y_new = np.zeros(n_new)\n",
    "        for i in range(n_new):\n",
    "            for j in range(self.n):\n",
    "                y_new[i] += self.alpha[j] * self.kernel(X_new[i], self.X[j])\n",
    "        return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
