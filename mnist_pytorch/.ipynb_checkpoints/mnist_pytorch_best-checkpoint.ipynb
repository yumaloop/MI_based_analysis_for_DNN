{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINE paper: https://arxiv.org/pdf/1801.04062.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Info\n",
      "=========\n",
      "- use_cuda:  True\n",
      "- Path:  /home/uchiumi/JNNS2019/mnist_pytorch\n",
      "- PyTorch 1.0.1.post2\n",
      "- Python:  3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Setting Info\")\n",
    "print(\"=========\")\n",
    "print(\"- use_cuda: \", use_cuda)\n",
    "print(\"- Path: \", os.getcwd())\n",
    "print(\"- PyTorch\", torch.__version__)\n",
    "print(\"- Python: \", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 128\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 100\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', \n",
    "                             train=True, \n",
    "                             download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "# test\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', \n",
    "                             train=False, \n",
    "                             download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer_values={}\n",
    "        layer_values[\"input_image\"]=x\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        layer_values[\"conv1_output\"]=x\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        layer_values[\"conv2_output\"]=x\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        layer_values[\"fc1_output\"]=x\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        layer_values[\"fc2_output\"]=x\n",
    "        x = F.log_softmax(x)\n",
    "        layer_values[\"output_softmax\"]=x\n",
    "        \n",
    "        return layer_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(1, n_epochs+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)[\"output_softmax\"]\n",
    "        train_loss = F.nll_loss(output, target)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0 and batch_idx != 0:\n",
    "            print('epoch: {} [{}/{} ]\\t train loss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset), train_loss.item()))\n",
    "            \n",
    "            train_losses.append(train_loss.item())\n",
    "            train_counter.append((batch_idx * batch_size_train) + ((epoch - 1)*len(train_loader.dataset)))\n",
    "            \n",
    "            torch.save(network.state_dict(), './results/model.pth')\n",
    "            torch.save(optimizer.state_dict(), './results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    nb_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            output = network(data)[\"output_softmax\"]\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            test_batch_loss = F.nll_loss(output, target, size_average=False).item() / batch_size_test\n",
    "            # test_loss /= len(test_loader.dataset)\n",
    "            # test_losses.append(test_loss)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            nb_correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            print('Test set: Avg. loss: {:.4f}, Accuracy: {}/{}'.format(test_batch_loss, nb_correct, batch_size_test * (batch_idx + 1)))\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uchiumi/.local/lib/python3.5/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 [12800/60000 ]\t train loss: 1.994762\n",
      "epoch: 1 [25600/60000 ]\t train loss: 1.181352\n",
      "epoch: 1 [38400/60000 ]\t train loss: 0.875294\n",
      "epoch: 1 [51200/60000 ]\t train loss: 0.774220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uchiumi/.local/lib/python3.5/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Avg. loss: 0.2927, Accuracy: 921/1000\n",
      "Test set: Avg. loss: 0.3153, Accuracy: 1843/2000\n",
      "Test set: Avg. loss: 0.2793, Accuracy: 2780/3000\n",
      "Test set: Avg. loss: 0.3264, Accuracy: 3697/4000\n",
      "Test set: Avg. loss: 0.3024, Accuracy: 4621/5000\n",
      "Test set: Avg. loss: 0.3586, Accuracy: 5523/6000\n",
      "Test set: Avg. loss: 0.3180, Accuracy: 6445/7000\n",
      "Test set: Avg. loss: 0.3521, Accuracy: 7353/8000\n",
      "Test set: Avg. loss: 0.3456, Accuracy: 8258/9000\n",
      "Test set: Avg. loss: 0.2955, Accuracy: 9187/10000\n",
      "epoch: 2 [12800/60000 ]\t train loss: 0.635417\n",
      "epoch: 2 [25600/60000 ]\t train loss: 0.456968\n",
      "epoch: 2 [38400/60000 ]\t train loss: 0.498270\n",
      "epoch: 2 [51200/60000 ]\t train loss: 0.338416\n",
      "Test set: Avg. loss: 0.1948, Accuracy: 946/1000\n",
      "Test set: Avg. loss: 0.1707, Accuracy: 1893/2000\n",
      "Test set: Avg. loss: 0.1690, Accuracy: 2838/3000\n",
      "Test set: Avg. loss: 0.1704, Accuracy: 3783/4000\n",
      "Test set: Avg. loss: 0.1592, Accuracy: 4736/5000\n",
      "Test set: Avg. loss: 0.1839, Accuracy: 5680/6000\n",
      "Test set: Avg. loss: 0.1832, Accuracy: 6631/7000\n",
      "Test set: Avg. loss: 0.1999, Accuracy: 7577/8000\n",
      "Test set: Avg. loss: 0.1691, Accuracy: 8517/9000\n",
      "Test set: Avg. loss: 0.1972, Accuracy: 9458/10000\n",
      "epoch: 3 [12800/60000 ]\t train loss: 0.439079\n",
      "epoch: 3 [25600/60000 ]\t train loss: 0.398442\n",
      "epoch: 3 [38400/60000 ]\t train loss: 0.335060\n",
      "epoch: 3 [51200/60000 ]\t train loss: 0.383405\n",
      "Test set: Avg. loss: 0.1603, Accuracy: 953/1000\n",
      "Test set: Avg. loss: 0.1193, Accuracy: 1914/2000\n",
      "Test set: Avg. loss: 0.1534, Accuracy: 2861/3000\n",
      "Test set: Avg. loss: 0.1332, Accuracy: 3821/4000\n",
      "Test set: Avg. loss: 0.1163, Accuracy: 4781/5000\n",
      "Test set: Avg. loss: 0.1553, Accuracy: 5735/6000\n",
      "Test set: Avg. loss: 0.1224, Accuracy: 6694/7000\n",
      "Test set: Avg. loss: 0.1274, Accuracy: 7657/8000\n",
      "Test set: Avg. loss: 0.1468, Accuracy: 8620/9000\n",
      "Test set: Avg. loss: 0.1754, Accuracy: 9569/10000\n",
      "epoch: 4 [12800/60000 ]\t train loss: 0.384390\n",
      "epoch: 4 [25600/60000 ]\t train loss: 0.459844\n",
      "epoch: 4 [38400/60000 ]\t train loss: 0.383510\n",
      "epoch: 4 [51200/60000 ]\t train loss: 0.241495\n",
      "Test set: Avg. loss: 0.0817, Accuracy: 976/1000\n",
      "Test set: Avg. loss: 0.1216, Accuracy: 1942/2000\n",
      "Test set: Avg. loss: 0.1343, Accuracy: 2895/3000\n",
      "Test set: Avg. loss: 0.1019, Accuracy: 3859/4000\n",
      "Test set: Avg. loss: 0.1215, Accuracy: 4824/5000\n",
      "Test set: Avg. loss: 0.0994, Accuracy: 5794/6000\n",
      "Test set: Avg. loss: 0.0963, Accuracy: 6761/7000\n",
      "Test set: Avg. loss: 0.1073, Accuracy: 7730/8000\n",
      "Test set: Avg. loss: 0.1182, Accuracy: 8688/9000\n",
      "Test set: Avg. loss: 0.1650, Accuracy: 9637/10000\n",
      "epoch: 5 [12800/60000 ]\t train loss: 0.240233\n",
      "epoch: 5 [25600/60000 ]\t train loss: 0.359475\n",
      "epoch: 5 [38400/60000 ]\t train loss: 0.304655\n",
      "epoch: 5 [51200/60000 ]\t train loss: 0.293656\n",
      "Test set: Avg. loss: 0.0915, Accuracy: 970/1000\n",
      "Test set: Avg. loss: 0.1133, Accuracy: 1942/2000\n",
      "Test set: Avg. loss: 0.1031, Accuracy: 2911/3000\n",
      "Test set: Avg. loss: 0.1320, Accuracy: 3872/4000\n",
      "Test set: Avg. loss: 0.0935, Accuracy: 4847/5000\n",
      "Test set: Avg. loss: 0.0983, Accuracy: 5814/6000\n",
      "Test set: Avg. loss: 0.0813, Accuracy: 6791/7000\n",
      "Test set: Avg. loss: 0.0870, Accuracy: 7752/8000\n",
      "Test set: Avg. loss: 0.0797, Accuracy: 8731/9000\n",
      "Test set: Avg. loss: 0.1216, Accuracy: 9692/10000\n",
      "epoch: 6 [12800/60000 ]\t train loss: 0.415077\n",
      "epoch: 6 [25600/60000 ]\t train loss: 0.262925\n",
      "epoch: 6 [38400/60000 ]\t train loss: 0.220016\n",
      "epoch: 6 [51200/60000 ]\t train loss: 0.215404\n",
      "Test set: Avg. loss: 0.0880, Accuracy: 974/1000\n",
      "Test set: Avg. loss: 0.0900, Accuracy: 1942/2000\n",
      "Test set: Avg. loss: 0.1105, Accuracy: 2909/3000\n",
      "Test set: Avg. loss: 0.0932, Accuracy: 3883/4000\n",
      "Test set: Avg. loss: 0.0824, Accuracy: 4855/5000\n",
      "Test set: Avg. loss: 0.0718, Accuracy: 5833/6000\n",
      "Test set: Avg. loss: 0.0924, Accuracy: 6805/7000\n",
      "Test set: Avg. loss: 0.0634, Accuracy: 7785/8000\n",
      "Test set: Avg. loss: 0.1090, Accuracy: 8755/9000\n",
      "Test set: Avg. loss: 0.1108, Accuracy: 9721/10000\n",
      "epoch: 7 [12800/60000 ]\t train loss: 0.231451\n",
      "epoch: 7 [25600/60000 ]\t train loss: 0.204727\n",
      "epoch: 7 [38400/60000 ]\t train loss: 0.152077\n",
      "epoch: 7 [51200/60000 ]\t train loss: 0.130020\n",
      "Test set: Avg. loss: 0.0763, Accuracy: 973/1000\n",
      "Test set: Avg. loss: 0.0691, Accuracy: 1950/2000\n",
      "Test set: Avg. loss: 0.0770, Accuracy: 2931/3000\n",
      "Test set: Avg. loss: 0.0784, Accuracy: 3905/4000\n",
      "Test set: Avg. loss: 0.1214, Accuracy: 4871/5000\n",
      "Test set: Avg. loss: 0.0643, Accuracy: 5855/6000\n",
      "Test set: Avg. loss: 0.0785, Accuracy: 6834/7000\n",
      "Test set: Avg. loss: 0.0970, Accuracy: 7799/8000\n",
      "Test set: Avg. loss: 0.0736, Accuracy: 8778/9000\n",
      "Test set: Avg. loss: 0.1034, Accuracy: 9746/10000\n",
      "epoch: 8 [12800/60000 ]\t train loss: 0.281359\n",
      "epoch: 8 [25600/60000 ]\t train loss: 0.313881\n",
      "epoch: 8 [38400/60000 ]\t train loss: 0.216292\n",
      "epoch: 8 [51200/60000 ]\t train loss: 0.169332\n",
      "Test set: Avg. loss: 0.0565, Accuracy: 982/1000\n",
      "Test set: Avg. loss: 0.0936, Accuracy: 1952/2000\n",
      "Test set: Avg. loss: 0.0599, Accuracy: 2929/3000\n",
      "Test set: Avg. loss: 0.0775, Accuracy: 3909/4000\n",
      "Test set: Avg. loss: 0.0679, Accuracy: 4891/5000\n",
      "Test set: Avg. loss: 0.0685, Accuracy: 5874/6000\n",
      "Test set: Avg. loss: 0.0872, Accuracy: 6848/7000\n",
      "Test set: Avg. loss: 0.0874, Accuracy: 7823/8000\n",
      "Test set: Avg. loss: 0.0696, Accuracy: 8803/9000\n",
      "Test set: Avg. loss: 0.1104, Accuracy: 9763/10000\n",
      "epoch: 9 [12800/60000 ]\t train loss: 0.352029\n",
      "epoch: 9 [25600/60000 ]\t train loss: 0.243979\n",
      "epoch: 9 [38400/60000 ]\t train loss: 0.214351\n",
      "epoch: 9 [51200/60000 ]\t train loss: 0.241155\n",
      "Test set: Avg. loss: 0.0788, Accuracy: 972/1000\n",
      "Test set: Avg. loss: 0.0507, Accuracy: 1955/2000\n",
      "Test set: Avg. loss: 0.0728, Accuracy: 2932/3000\n",
      "Test set: Avg. loss: 0.0711, Accuracy: 3908/4000\n",
      "Test set: Avg. loss: 0.0579, Accuracy: 4892/5000\n",
      "Test set: Avg. loss: 0.0933, Accuracy: 5872/6000\n",
      "Test set: Avg. loss: 0.0681, Accuracy: 6850/7000\n",
      "Test set: Avg. loss: 0.0691, Accuracy: 7831/8000\n",
      "Test set: Avg. loss: 0.0676, Accuracy: 8811/9000\n",
      "Test set: Avg. loss: 0.0855, Accuracy: 9785/10000\n",
      "epoch: 10 [12800/60000 ]\t train loss: 0.173273\n",
      "epoch: 10 [25600/60000 ]\t train loss: 0.112748\n",
      "epoch: 10 [38400/60000 ]\t train loss: 0.281802\n",
      "epoch: 10 [51200/60000 ]\t train loss: 0.215120\n",
      "Test set: Avg. loss: 0.0903, Accuracy: 970/1000\n",
      "Test set: Avg. loss: 0.0577, Accuracy: 1952/2000\n",
      "Test set: Avg. loss: 0.0607, Accuracy: 2931/3000\n",
      "Test set: Avg. loss: 0.0406, Accuracy: 3919/4000\n",
      "Test set: Avg. loss: 0.0606, Accuracy: 4904/5000\n",
      "Test set: Avg. loss: 0.0718, Accuracy: 5879/6000\n",
      "Test set: Avg. loss: 0.0667, Accuracy: 6854/7000\n",
      "Test set: Avg. loss: 0.0564, Accuracy: 7836/8000\n",
      "Test set: Avg. loss: 0.0604, Accuracy: 8820/9000\n",
      "Test set: Avg. loss: 0.0896, Accuracy: 9796/10000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    model_train(epoch)\n",
    "    model_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model's Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VGXWwPHfIQSCdEgUly7qKkUpMeqKBQt2sQsKKurLrmJ/911B3bWwRV0XGyoioqIgYkdXxA52CEgTRBBBgkiVIlJSzvvH8wxMwszkJpnJTJLz/XzuJzO3njszmTNPuc8VVcUYY4wpTa1kB2CMMaZqsIRhjDEmEEsYxhhjArGEYYwxJhBLGMYYYwKxhGGMMSYQSxjGGGMCsYRhjDEmEEsYxhhjAqmd7ADiKTMzU9u1a5fsMIwxpsqYOXPmOlXNCrJutUoY7dq1Izc3N9lhGGNMlSEiy4Oua1VSxhhjArGEYYwxJhBLGMYYYwKpVm0YxpjqIT8/n7y8PLZv357sUKqNjIwMWrVqRXp6ern3kbCEISKtgbHAPoACo1T1oRLrCPAQcBrwG3C5qs7yyy4Dbver/l1Vn01UrMaY1JKXl0fDhg1p164d7mvCVISqsn79evLy8mjfvn2595PIKqkC4H9VtSNwBDBYRDqWWOdU4AA/DQIeBxCRZsAdwOFADnCHiDRNYKzGmBSyfft2mjdvbskiTkSE5s2bV7jElrCEoaqrQqUFVd0CLARallitDzBWnS+BJiKyL3Ay8J6qblDVX4D3gFMSFasxJvVYsoiveLyeldLoLSLtgG7AVyUWtQRWhD3P8/OizY87VRg2DKZMScTejTGm+kh4whCRBsArwI2qujkB+x8kIrkikrt27dpybA/33w+TJ8c7MmNMVbV+/Xq6du1K165dadGiBS1bttz1fOfOnYH2MXDgQBYtWhT4mKNHj+bGG28sb8iVIqG9pEQkHZcsxqnqqxFWWQm0Dnveys9bCRxXYv7HkY6hqqOAUQDZ2dlanjgzM6EcucYYU001b96c2bNnA3DnnXfSoEED/vznPxdbR1VRVWrVivy7++mnn054nJUtYSUM3wPqKWChqg6Pstok4FJxjgA2qeoqYArQW0Sa+sbu3n5eQmRmwrp1idq7Maa6WLJkCR07duSSSy6hU6dOrFq1ikGDBpGdnU2nTp24++67d63bs2dPZs+eTUFBAU2aNGHIkCEceuihHHnkkaxZsybwMZ9//nm6dOlC586dufXWWwEoKChgwIABu+Y//PDDADzwwAN07NiRQw45hP79+8f35ElsCeMoYAAwT0Rm+3m3Am0AVHUk8DauS+0SXLfagX7ZBhEZBszw292tqhsSFWhWFqxalai9G2Mq4sYbYfbs0tcri65d4cEHy7ftt99+y9ixY8nOzgbgnnvuoVmzZhQUFNCrVy/OP/98OnYs3iF006ZNHHvssdxzzz3cfPPNjBkzhiFDhpR6rLy8PG6//XZyc3Np3LgxJ554Im+99RZZWVmsW7eOefPmAbBx40YA7rvvPpYvX06dOnV2zYunRPaS+lRVRVUPUdWufnpbVUf6ZIHvHTVYVTuoahdVzQ3bfoyq7u+nhJbtrErKGBNUhw4ddiULgBdeeIHu3bvTvXt3Fi5cyIIFC/bYpl69epx66qkA9OjRg2XLlgU61ldffcXxxx9PZmYm6enpXHzxxUybNo3999+fRYsWcf311zNlyhQaN24MQKdOnejfvz/jxo2r0AV60diV3liVlDGprLwlgUSpX7/+rseLFy/moYceYvr06TRp0oT+/ftHvNahTp06ux6npaVRUFBQoRiaN2/O3LlzmTx5Mo8++iivvPIKo0aNYsqUKUydOpVJkybxz3/+k7lz55KWllahY4WzsaRwVVLbtsHWrcmOxBhTlWzevJmGDRvSqFEjVq1axZQ4988//PDD+eijj1i/fj0FBQVMmDCBY489lrVr16KqXHDBBdx9993MmjWLwsJC8vLyOP7447nvvvtYt24dv/32W1zjsRIGroQBrpQR9uPBGGNi6t69Ox07duSggw6ibdu2HHXUURXa31NPPcXLL7+863lubi7Dhg3juOOOQ1U588wzOf3005k1axZXXnklqoqIcO+991JQUMDFF1/Mli1bKCoq4s9//jMNGzas6CkWI6rl6omakrKzs7U8N1CaNAn69IHcXOjRIwGBGWPKZOHChRx88MHJDqPaifS6ishMVc2OskkxViXF7hKGNXwbY0x0ljAoXiVljDEmMksYuEZvsBKGMcbEYgkDaNwY0tKshGGMMbFYwgBq1bJrMYwxpjSWMDy72tsYY2KzhOFZCcMYExKP4c0BxowZw88//xxxWf/+/Xn99dfjFXKlsAv3vKws+OabZEdhjEkFQYY3D2LMmDF0796dFi1axDvEpLAShmdVUsaYIJ599llycnLo2rUr11xzDUVFRRGHG3/xxReZPXs2F110UeCSSVFRETfffDOdO3emS5cuu676XrlyJT179qRr16507tyZzz//POoQ54lkJQwvMxM2bIDCQtdjyhiTIlJofPP58+fz2muv8fnnn1O7dm0GDRrEhAkT6NChwx7DjTdp0oRHHnmEESNG0LVr10D7f+mll1i4cCFz5sxh7dq1HHbYYRxzzDE8//zznHnmmdxyyy0UFhaybds2Zs6cGXGI80SyEoaXlQVFRfDLL8mOxBiTqt5//31mzJhBdnY2Xbt2ZerUqXz//fdRhxsvq08//ZR+/fqRlpZGixYt6NmzJ7m5uRx22GGMHj2au+66i/nz59OgQYO4HbMsrIThhV/tHXpsjEkBKTS+uapyxRVXMGzYsD2WRRpuPF6OP/54Pv74Y/773/9y6aWX8pe//IVLLrkkoceMxEoYXuhqb+spZYyJ5sQTT2TixIms818U69ev58cff4w43DhAw4YN2bJlS+D9H3300UyYMIGioiJWr17NZ599RnZ2NsuXL6dFixYMGjSIgQMH8vXXX0c9ZiIlrIQhImOAM4A1qto5wvL/Ay4Ji+NgIMvfnnUZsAUoBAqCjqRYETYAoTGmNF26dOGOO+7gxBNPpKioiPT0dEaOHElaWtoew40DDBw4kKuuuop69eoxffr0YjdSArjqqqu49tprAWjfvj1Tp07lyy+/5JBDDkFEGD58OHvvvTdjxoxh+PDhpKen07BhQ5577jlWrFgR8ZiJlLDhzUXkGOBXYGykhFFi3TOBm1T1eP98GZCtqmX6vV/e4c0BVqyANm1g1Cj4n/8p1y6MMXFiw5snRsoOb66q04ANAVfvB7yQqFiCsBKGMcbElvQ2DBHZCzgFeCVstgLvishMERlUyvaDRCRXRHLXVuDbvl49d7c9a8MwxpjIkp4wgDOBz1Q1vDTSU1W7A6cCg331VkSqOkpVs1U1OyvUcl1OWVmWMIxJFdXpbqCpIB6vZyokjL6UqI5S1ZX+7xrgNSCnMgKxq72NSQ0ZGRmsX7/ekkacqCrr168nIyOjQvtJ6nUYItIYOBboHzavPlBLVbf4x72BuysjHhuA0JjU0KpVK/Ly8qhINbMpLiMjg1atWlVoH4nsVvsCcByQKSJ5wB1AOoCqjvSrnQO8q6pbwzbdB3hNRELxjVfVdxIVZ7isLPj228o4kjEmlvT0dNq3b5/sMEwJCUsYqtovwDrPAM+UmLcUODQxUcVmVVLGGBNdKrRhpIzMTNi6FbZtS3YkxhiTekpNGCJSX0Rq+ccHishZIpKe+NAqnw0PYowx0QUpYUwDMkSkJfAuMIAS1UjVRfgAhMYYY4oLkjBEVX8DzgUeU9ULgE6JDSs5rIRhjDHRBUoYInIkbqDA//p51fIWQzY8iDHGRBckYdwIDAVeU9VvRGQ/4KPEhpUcViVljDHRldqtVlWnAlMBfOP3OlW9PtGBJUPTplCrlpUwjDEmkiC9pMaLSCN/1fV8YIG/l0W1k5YGzZpZCcMYYyIJUiXVUVU3A2cDk4H2uJ5S1ZINQGiMMZEFSRjp/rqLs4FJqpqPG368WrKrvY0xJrIgCeMJYBlQH5gmIm2BzYkMKplsAEJjjIms1IShqg+raktVPU2d5UCvSogtKaxKyhhjIgvS6N1YRIaH7monIv/BlTaqpVAJo6go2ZEYY0xqCVIlNQbYAlzop83A04kMKpkyM6GwEDZtSnYkxhiTWoIMb95BVc8Le36XiMxOVEDJFhoeZO1ad12GMcYYJ0gJY5uI9Aw9EZGjgGo7ALhd7W2MMZEFSRhXA4+KyDIRWQ6MAP5U2kYiMkZE1ojI/CjLjxORTSIy209/C1t2iogsEpElIjIk6MnEgw1AaIwxkQUZGmQ2cKiINPLPg3apfQaXXMbGWOcTVT0jfIaIpAGPAicBecAMEZmkqgsCHrdCbABCY4yJLGrCEJGbo8wHQFWHx9qxqk4TkXbliCkHWOJv1YqITAD6AJWaMKyEYYwxxcWqkmpYyhQPR4rIHBGZLCKhe2y0BFaErZPn51WK+vWhXj0rYRhjTElRSxiqeleCjz0LaKuqv4rIacDrwAFl3YmIDAIGAbRp0yYugdnV3sYYs6cgjd4JoaqbVfVX//ht3JhVmcBKoHXYqq38vGj7GaWq2aqanRVqsa4gSxjGGLOnpCUMEWkhvkFERHJ8LOuBGcABItJeROoAfYFJlRlbVpZVSRljTElBLtwrFxF5ATgOyBSRPOAOIB1AVUcC5wNXi0gB7rqOvqqqQIGIXAtMwd0KdoyqfpOoOCPJzIQlSyrziMYYk/rK3EsqJEAvqX6lLB+B63YbadnbwNuxtk8kG4DQGGP2FKuEEeoJ9XvgMHZXC50JTE9kUMmWmQmbN8OOHVC3brKjMcaY1FBqLykRmQZ0V9Ut/vmdwH8rJbokCV2LsX49/O53yY3FGGNSRZBG732AnWHPd/p51Vb4AITGGGOcII3eY4HpIvIaILirrp9JZFDJZld7G2PMnoKMJfUPEZkMHI27l/dAVf064ZElkQ1AaIwxewrarbYQKMIljGp/LzobgNAYY/YU5BatNwDjgExgb+B5Ebku0YElU7Nm7q+VMIwxZrcgJYwrgcNVdSuAiNwLfAE8ksjAkql2bZc0rIRhjDG7BeklJbgqqZBCP69as/GkjDGmuCAljKeBr0r0knoqoVGlAEsYxhhTXJBeUsNF5GOgJzWklxS4nlJLlyY7CmOMSR1BR6stxCWLGtFLCqyEYYwxJVkvqShCAxCqJjsSY4xJDdZLKorMTMjPd4MQNm6c7GiMMSb5rJdUFDY8iDHGFFfWXlIAZ1MDekmFD0DYoUNyYzHGmFQQtJfUVOAoP6tG9JKyEoYxxhQXdCyp2cCq0Poi0kZVf4y1gYiMAc4A1qhq5wjLLwFuwVVvbQGuVtU5ftkyP68QKFDV7IBxxo0NQGiMMcWVmjB8j6g7gNXsbr9Q4JBSNn0GdwvWsVGW/wAcq6q/iMipwCjg8LDlvVQ1aV/XNgChMcYUF6SEcQPwe1VdX5Ydq+o0EWkXY/nnYU+/BFqVZf+J1qAB1KljJQxjjAkJ0ktqBbApwXFcCUwOe67AuyIyU0QGJfjYEYnsvhbDGGNMjBKGiNzsHy4FPhaR/wI7QstVdXg8AhCRXriE0TNsdk9VXSkiewPvici3qjotyvaDgEEAbdq0iUdIu2RmWpWUMcaExCphNPTTj8B7QJ2weQ3jcXAROQQYDfQJr/JS1ZX+7xrgNSAn2j5UdZSqZqtqdlaopTpObHgQY4zZLWoJQ1XvSuSBRaQN8CowQFW/C5tfH6ilqlv8497A3YmMJZqsLMjNTcaRjTEm9cSqknpQVW8UkTdxbQrFqOpZsXYsIi8AxwGZIpKH62mV7rcdCfwNaA48JiKwu/vsPsBrfl5tYLyqvlP2U6s4K2EYY8xusXpJPef/3l+eHatqv1KWXwVcFWH+UuDQ8hwz3rKyYONGN6ZUenqyozHGmOSKVSU10/+dWnnhpJbQtRjr10OLFsmNxRhjki1WldQ8IlRF4S/cU9XSLtyr8vbe2/1dtcoShjHGxKqSOqPSokhRh/qKsVmzoFu35MZijDHJFrVbraouD01+1gH+8RpgQ6VEl2T77w9NmsD06cmOxBhjki/IHff+B3gZeMLPagW8nsigUoUI5ORYwjDGGAg2NMhg3NDmmwFUdTHuVq01Qk4OzJsHv/2W7EiMMSa5giSMHaq6M/RERGoTuTG8WsrJgcJC145hjDE1WZCEMVVEbgXqichJwEvAm4kNK3Xk+EFJrFrKGFPTBUkYQ4C1wDzgj8DbqnpbQqNKIfvsA23bWsIwxpgg98PopqpPAk+GZojIGar6VuLCSi3W8G2MMcFKGE+KyK5brIpIP+CviQsp9eTkwA8/2FDnxpiaLUjCOB8YKyIH+S621+BGkK0xrB3DGGMCJAw/GGBf3FDk5wG9VTXRd+BLKd27Q61aljCMMTVbWcaSagakAV+JCDVhLKmQBg2gUydLGMaYms3GkgooJwdeew1U3RXgxhhT08SqkvrFjx21JcpUoxx+OGzYAEuXJjsSY4xJjlgljPG4UsZMXNVU+O9qBfZLYFwpJ9Tw/dVX0KFDcmMxxphkiDVa7Rn+b3tV3c//DU2BkoWIjBGRNSIyP8pyEZGHRWSJiMwVke5hyy4TkcV+uqysJxZvnTpBvXrWjmGMqbliNXp3j7YMQFWDjK70DDACGBtl+anAAX46HHgcOFxEmuHuAZ6NK83MFJFJqvpLgGMmRO3a0KOHJQxjTM0Vq0rqPzGWKXB8aTtX1Wki0i7GKn2AsaqqwJci0kRE9gWOA95T1Q0AIvIecArwQmnHTKScHHj0UbvHtzGmZop1T+9elXD8lsCKsOd5fl60+XsQkUHAIIA2bdokJkovJweGD3fDnXePWf4yxpjqJ8iV3ilNVUeparaqZmdlZSX0WHbFtzGmJkt2wlgJtA573srPizY/qdq1g6ws11PKGGNqmmQnjEnApb631BHAJlVdBUwBeotIUxFpihu7akoyAwW7ZasxpmYrdXjzKL2lNgHLVbWglG1fwDVgZ4pIHq7nUzqAqo4E3gZOA5YAvwED/bINIjIMmOF3dXeoATzZcnLg7bdh82Zo1CjZ0RhjTOUJcj+Mx4DuwFzcxXudgW+AxiJytaq+G21DVe0Xa8e+d9TgKMvGAGMCxFepcnLc8CAzZ0KvyugWYIwxKSJIldRPuJsoZatqD6AbsBQ4CbgvkcGlosMOc3+tWsoYU9MESRgHquo3oSequgA4yA97XuM0b+6GBrGEYYypaYJUSX0jIo8DE/zzi4AFIlIXyE9YZCksJwemTUt2FMYYU7mClDAuxzVK3+inpX5ePlAja/EPPxxWrnSTMcbUFKWWMFR1m4g8AryLGxJkkaqGSha/JjK4VBW6gG/GDGgZ8fpzY4ypfkotYYjIccBi3CCCjwHficgxCY4rpXXt6gYjtHYMY0xNEqQN4z+4+3gvAhCRA3GDAPZIZGCprF49OOQQ+OSTZEdijDGVJ0gbRnooWQCo6nf4i+9qsosugk8/hddfT3YkxhhTOYIkjFwRGS0ix/npSSA30YGluptucqWMwYNh06ZkR2OMMYkXJGFcDSwArvfTAj+vRktPh9Gj4eefYciQZEdjjDGJV2rCUNUdqjpcVc/10wOquqMygkt1hx0GN94II0dae4YxpvoTN5xThAUi83DdaCNS1UMSFVR5ZWdna25u5daWbd0KnTtD3bowezZkZFTq4Y0xpkJEZKaqZgdZN1YvqTPiFE+1Vr8+PPEEnHwy/OMfMGxYsiMyxpjEiHWL1uWVGUhV1rs3XHop3HMPXHghdOmS7IiMMSb+kn0DpWpj+HBo2hSuugoKC5MdjTHGxJ8ljDhp3hweeshd/T1iRLKjMcaY+AuUMESknoj8vqw7F5FTRGSRiCwRkT06n4rIAyIy20/ficjGsGWFYcsmlfXYydC3L5x2Gtx2GyxbluxojDEmvoKMJXUmMBt4xz/vGuQLXETSgEeBU4GOQD8R6Ri+jqrepKpdVbUr8AjwatjibaFlqnpW4DNKIhF4/HGoVctdCb7DOh8bY6qRICWMO4EcYCOAqs4G2gfYLgdYoqpLVXUn7n4afWKs3w83RlWV1qYNPPusq5q6/vpkR2OMMfETJGHkq2rJwS+iXp8RpiWwIux5np+3BxFpi0tCH4bNzhCRXBH5UkTODnC8lHHOOTB0KIwaBWNS7q7kxhhTPkHvuHcxkCYiB+CGB/k8znH0BV5W1fD+RW1VdaWI7Ad8KCLzVPX7khuKyCBgEECbNm3iHFb5DRsGublwzTVuzKnsQJfFGGNM6gpSwrgO6ATsAMYDm3B33ivNSqB12PNWfl4kfSlRHaWqK/3fpcDHQLdIG6rqKFXNVtXsrKysAGFVjrQ0GD8eWrSA886DdeuSHZExxlRMkIRxkKrepqqH+el2Vd0eYLsZwAEi0l5E6uCSwh6N5SJyENAU+CJsXlN/z3BEJBM4CjfoYZWSmQmvvgqrV7seVAUFyY7IGGPKL0jC+I+ILBSRYSLSOeiOVbUAuBaYAiwEJqrqNyJyt4iE93rqC0zQ4oNaHYwbVn0O8BFwj6pWuYQB0L27G5zwgw/g9tuTHY0xxpRf1MEHi60k0gK4ELgIaAS8qKp/T3BsZZaMwQeDuvpqlzheftlVURljTCooy+CDgS7cU9WfVfVh4E+4azL+VoH4aqQHH4QjjoDLL4eFC5MdjTHGlF2QC/cOFpE7/XDnj+B6SLVKeGTVTN26rnSx115w7rmweXOyIzLGmLIJUsIYg7to72RVPU5VH1fVNQmOq1pq2RImToTFi2HgQAhQG2iMMSkjyB33jlTVB1X1p8oIqLo79lj4979d76n77kt2NMYYE1zUC/dEZKKqXhjhznsCaCreca+quPFGN3TIrbdCjx5w4onJjsgYY0oX60rvG/xfu/NenInA6NEwf767PmPmTGjbNtlRGWNMbFGrpFR1lX94jaouD5+AayonvOqrfn1XLZWfDzffnOxojDGmdEEavU+KMO/UeAdSEx1wgLtD35tvwvr1yY7GGGNii5owRORq337xexGZGzb9AMytvBCrtwEDXClj4sRkR2KMMbFFvdJbRBrjxnj6FxB+t7wtqrqhEmIrs1S+0jsaVejSBRo3hs8+S3Y0xpiaJi5XeqvqJlVdpqr9fLvFNlxvqQYikjrjiFdxIq6U8fnn8P0eg7cbY0zqCHSLVhFZDPwATAWWAZMTHFeNcsklLnE8/3yyIzHGmOiCNHr/HTgC+E5V2wMnAF8mNKoaplUr6NULnnvOrv42xqSuoLdoXQ/UEpFaqvoRYPePi7MBA1yV1JeWio0xKSpIwtgoIg2AacA4EXkI2JrYsGqe886DevVcKcMYY1JRkITRB9fgfRPwDvA9cGYig6qJGjaEs8+GF1+EnTuTHY0xxuwpyOCDW1W1UFULVPVZVX3YV1GZOBswADZsgLffTnYkxhizpyC9pLaIyOYS0woReU1E9itl21NEZJGILBGRIRGWXy4ia0Vktp+uClt2mYgs9tNl5Tu9quWkk2CffaxayhiTmmINPhjyIJAHjMeNVNsX6ADMwt0r47hIG4lIGvAobmiRPGCGiEyKcG/uF1X12hLbNgPuwDWuKzDTb/tLwPOqkmrXhn794LHH4JdfoGnTZEdkjDG7BWnDOEtVn1DVLaq6WVVH4W6m9CLuSvBocoAlqrpUVXcCE3DtIUGcDLynqht8kngPOCXgtlXagAGuDSPWUCE7d8KmTZUXkzHGQLCE8ZuIXCgitfx0IbDdL4t11UBLYEXY8zw/r6Tz/BhVL4tI6zJui4gMEpFcEcldu3ZtgNNJbd26QceO0aulPvgADj4YOneGHTsqNzZjTM0WJGFcAgwA1gCr/eP+IlIPuDbWhgG8CbTzN2N6D3i2rDtQ1VGqmq2q2VlZWRUMJ/lEoH9/N67U0qW7569fD5df7m62tHUr5OXBa68lLUxjTA0UpJfUUlU9U1UzVTXLP16iqttU9dMYm64EWoc9b+Xnhe97vaqGfiePBnoE3bY6u+QS93fcOHfl9wsvuFLFuHEwdKhLJPvtByNHJjdOY0zNEqSX1IEi8oGIzPfPDxGR2wPsewZwgIi0F5E6uMbySSX2vW/Y07OAhf7xFKC3iDQVkaZAbz+vRmjTBo47Dp55Bk4/HS6+GNq1c3fm++c/Ya+9YNAgmDoVvv02ycEmwIoVUFCQ7CiMMSUFqZJ6EhgK5AOo6lzcl39MqlqAq7KagksEE1X1GxG5W0TO8qtdLyLfiMgc4Hrgcr/tBmAYLunMAO5O1SHVE2XAAFeSmDYNHnwQvvgCDgm7i/rAgZCeDk88kbwYE2HKFGjfHs49FwoLkx2NMSZc1Pth7FpBZIaqHiYiX6tqNz9vtqp2rZQIy6Aq3g8jmh074NFH3ZAh0e733bev+4L96Sc3rEhZ7dzp2kzS0ysWa7zMmwdHHeVKUKtXu1vX/uc/yY7KmOotLvfDCLNORDrge0SJyPnAqtibmIqqW9d9YUZLFgB/+hNs3Fi+u/UtX+5KLB06wKRJpa+faKtWwRlnuCFScnPhuutg+HAYNSrZkRljQoIkjMHAE8BBIrISuBG4OqFRmUCOPRZ+//uyV0stWOB+ya9eDY0aQZ8+riSzMkndCrZuhbPOcj3B3nzTDfc+fDiceipccw28/35y4jLGFBe0l9SJQBZwkKr2VNVlCY/MlEoE/vhH174xZ06wbb76Co4+GoqKXPvI11/Dv/7lxq86+GAYMaJy2w4KC1034lmzXG+w7t3d/Nq1YcIEF9P558PChbH3U1XMmgX/+Id7/Y2paoL0kqorIhcDNwA3icjfRORviQ/NBHHZZa76Kkgp49134YQT3JAjn37q7iWeng5DhsD8+XDEEa4q6A9/CJ6AKuqWW+D11+GBB+DMEmMgN2oEb70FGRmut1hVvy5z4UI3Xtjtt8N77yU7GmPKLkiV1Bu4IT0KcPfBCE0mBTRrBhdd5K4M37Il+noTJ7o2gv33d8livxLDRnbo4BrQx42DH36AHj0S334wcqRr1L72Wrj++sjrtG0Lb7zh2jjOOafqXt2+ciWcfLJL0FlZ8MgjyY7ImLJ7nwmNAAAblUlEQVQL0ktqvqp2rqR4KqQ69ZIqiy++cKWCJ55w12eU9PjjMHiwa7d4801o0iT2/jZscNVEkye7KqrBg4PF8cknMHeuq24pLHR/Sz4OPf/1V9dd+JRTXAmjdinDYE6c6BJj//4wdqyrjqsqNm501YDLl7trZ15/HYYNg8WLXaI2JpnK0ksKVY05AaOALqWtlwpTjx49tCYqKlLt0kW1Wzf3OHz+sGGqoHrGGapbtwbf5/btqn36uG2HD4+97o4dqjfd5NYty3TUUaqbNweP6c473Xbvvx98m2Tbtk31mGNU09NV33vPzVu5UrV2bfeaGZNsQK4G/I4NkjAWADuBRcBcYB4wN+gBKnOqqQlDVfXRR927OX26e15YqHrDDW7egAGqO3eWfZ87dqied57bx733Rl5n6VLVnBy3znXXqf70k+rataobNqhu3OgSwtat7otzxw7V/PziSa0stm1T3Wcf1ZNPLt/2la2gQPXcc91r88ILxZf17avauLHqli3Jic2YkHgnjLaRpqAHqMypJieMTZtU69dXveIKlxz693fv7o03uuRRXvn57ssNXGkl3Kuvui+9xo1VX3mlYvEH9Y9/uFjmzIn/vnfuVD3uONU//tElt4ooKlK95hoX6wMP7Ln8s8/csscfr9hxTDDr1yc7gtQV14RRlaaanDBUVa+6SrVePdVTTnHv7D/+Uf5f8+Hy83cnoL/9zVVXXXede37YYa6UUVnWr3eJ8dJL47/vUCkNXDXSunXl39ff/+7285e/RF5eVKTavbtqp07xeY9MdB99pJqWpjpiRLIjSU2WMGqo3Fz3joqojhwZ330XFKgOHOj237Kl7iq9VPSXeHlcf71rA1ixIn773LxZde+9XaIYN061Th3V/fdXXbSo7Pt66indVRUYq3T39NNuvQ8+KHfYphQ7d6p27Ohe50aNVFetSnZEqccSRqqpxJ+Qd9+t+sYbidl3YaGrZsnMVH399cQcI4gffnC/GP/85/jt84473H/Dl1+65599ppqVpdq0qeqHHwbfz5tvuthOPrn0dqNt29xrefbZ5Q7blOI//3Hv6/33ux8BiSiZVnWWMFLN+PGqJ5yg+s471aL+oSJtIvHSt69qw4auYb2iVq1y1Vznn198/tKl7tdp7dqqo0eXvp/PP3dVgtnZwRuzhw5VrVVLddmyssddXfz8c2KqNVeuVG3QQPW009y/3a23um+8Tz6J/7GqMksYqea551T33de93Icc4p6Xp9uS2SVU/fbvf1d8X1df7ZLCd9/tuWzjRtXevd2xbrpJde7cyNVwCxeqNmvmqrFWrw5+7B9/dCWSaG0d1dlPP7mefBkZrroonlWMqqoXX6xat67qkiXu+a+/qrZu7f4F8/Pje6yqzBJGKtq+XXXMmN0Vqq1bu/JyWS5EMMX06uXaUyrSjrJokfvCvuaa6Ovk5+/u8QQuuRx8sOoFF7hrQ8aPV23TxnX5/f77ssdw3nku2fz2W/nPoypZtcq1f2VkuNe+f3/VvfZSPfXU+BXAP/7YvVd//Wvx+a+84uY//HB8jlMdWMJIZYWFqm+9pXrsse7lb9xY9ZZbXPnZlMnbb7uX8Nlny7+P885z1RY//1z6ugsWuOspbrvNXdS4//6ugwG46rFZs8oXQ+jLLUi1V1X288+qN9/squ3S0lQvv1x18WK37JFH3Gvw9NMVP87OnaqdO6u2bbvnxapFRa7E2KhRsPe8JkiZhAGc4i/4WwIMibD8Zn9h4Fzgg/DrO4BCYLafJgU5XpVIGOGmT3c/U2vVcpcCDxyo+s03yY6qyigqcl8MXbqU75fpF1+4/4A77yx/DFu3uuqxiuT70JX6hx5aLZq4Ivr0U1eKqFXLNTyHEkVIYaHroda4sWpeXsWO9cAD7n197bXIyxctcv9ul11WseMk0sUXq55zjusYkWgpkTCANOB7YD+gDjAH6FhinV7AXv7x1cCLYct+Lesxq1zCCFmyRHXwYPfTC1RPP9397Kyu3x5xFOqa+s47ZduuqEj16KNdNVIqXG09apRW2wbZDRtcDWyHDpHbiUIWL3b/AqefXv6P/qpVrvRwyimx9zF0qHu9P/20fMdJpCVLdFf152mnudrsREqVhHEkMCXs+VBgaIz1uwGfhT2vOQkjZO1a93M3M9O9NTk5qi+95C6CMBHt2KH6u9+5TmhlMWmSe4kfeywxcZXV1q2uC2/HjuWv2kpFRUWu91nt2ruHrYnlwQfd+zJ2bPmON2CA6z4bKzGp7m4AP/TQ1GsAv/12VxK76y73WvTpk9g+MqmSMM4HRoc9HwCMiLH+COD2sOcFQC7wJXB2kGNW+YQRsnWr+ybr0MG9RR06uMuQyzJ6YA1y773uZZo5M9j6+fnui/nAA1Ors9qUKaotWrj6/dtvT/wvy8rw5JPuvbnnnmDrFxaq9uyp2qSJ60VVFtOmuWPdemuw9V96ya3/yCNlO04iFRSotmrlOgCo7m7bueCCxCW2KpcwgP4+MdQNm9fS/90PWAZ0iLLtIJ9Yctu0aZOAlzOJCgpUX35Z9fDD3VuVmemuMFuzJtmRpZRffnEN16Furb//vUsIXbqodu2q2qOHK6wdcYQbIbdHD/dyvvxysiPf0/r1ro4fXPvMjBnJjqj8Fi507RYnnFC2a3e++871oDrzzOBVU/n57v1u3dqVHoIoKlI96aSyNR/+9JO7OLZXL9cBIt61xu+84977l17aPe/++928/v0TU9mQKgkjUJUUcCKwENg7xr6eAc4v7ZjVpoRRUlGR+/l05pnuLcvIcBcPlGw5rMFeeMH9Q/Xrp3rhha7309lnu5fstNPcldcnnuj+0Y85xg0wmMpNRG+95ara0tJcfXtZSxsFBa6L7+TJrgvptde61+Dww11v7kQPxrd9u0vWzZuXr0NA6Art558Ptv5DD7n1yzoI5po1pTcfFhW5eRde6KrWwofH6d1793Ue8XDBBe41K/l+hwbdvPLK+F84myoJozawFGgf1ujdqcQ63XzD+AEl5jcNlTaATGBxyQbzSFO1TRjhFixwn5o6dVyfzvPPV/3qq2RHZRLgl1/c6MPgSk1XXeUu8LvnHlfV88orbmC9Dz9UfeIJN1TKWWepHnSQ+3iE33ukYUM32GF29u7fHAMHBmtXKI/Q/VEmTSrf9gUFqkce6dp1Squa+vln19Ddu3f5fwSsXevaDELNh4cdpvrii27AwtClU02auG7B333n4nv4Yfe6ZmS4wSYrOq7a2rWutHPDDZGX//WvLo6rr47vj52USBguDk4DvvNJ4TY/727gLP/4fWB1ye6zwB9w992Y4/9eGeR4NSJhhPz0k/vp2aSJ7hpe9c03U2PcDhNXkye7L/oWLdwXSrQbUtWt60a/Peccd2nP6NGuYLpqVfEvmNmzXQmrfn23XXa2u6Y0XhcOTp7s9jt4cMX28+237su4XTs37Eo0l13mXpfyDBRZ0m+/uSHn999/9+vao4d7fSI1Ieblud9s4C7mnDq1/McOlZJmz468vKjI/WAA9wMhXlImYVT2VKMSRsjmze6WeK1b7/7UPvVU9WgxNXsoKnJ19D/+qPr1126k2/ffd2NRlfW3wqZN7hd0p07uo7Pffqrz5lUsvp9/dqP+du4cnwT0xRcuYaSluWqZknX4ofuKDBlS8WOFKyhw7QlBS2D//a+LE1zJbe3ash2vqMgNWVLaV1hRkfshEM/rMyxh1EQ7d7oK30MPdW/rvvuq/utfrl7DmBiKilTffdd9ZOrXdzfGKo/CQtdOkpGhOn9+/OLbuHH3Tbx69dp9YV9+vmsnadUqeEN3Im3d6kp2tWu7doinnw5edTRzpiatm7cljJos9N9/0knu7W3QwA2ENHKk+8m0aJGVPkxEK1fuvt3unXeWvcQSaqhOxJdeUZH7Aq5f330ZT5q0u8vpxInxP15FzJun+oc/uNiOPdb1FivN4MEu0Sbj950lDON8/bXqJZfs2QIKrgvOUUe5rkW33+6qsT780I0znWpXMplKs23b7m69554b/Cr4WbNcO8LZZye299miRarduumuNpsTTkjN3m6Fhe7q/aZN3esSq81h2zbXFHnxxZUXX7iyJAxx61cP2dnZmpubm+wwUk9hIaxaBT/84KZly4o/XrECiop2r5+WBq1bQ/v20K6d+xv+eN99oVat5JyLSThVeOgh+N//hY4d4Y03YL/9oq+/dSv06AG//gpz5kDz5omNb8cOuPVWGDcOPvoIDj44sceriDVr4PLLYfJkuOceuOWWPdeZMAH69YP334cTTqj0EBGRmaqaHWhdSxiG/HyXNMITSXhiWbWq+Pp16kDbtnsmktDjrCwQqfzzMHH13ntw0UXurfy//3OP27ffc72rroIxY+CDD6BXr8qLT7VqfMzy813SGD8ehgyBf/6zeNy9e8N338HSpcn5HVaWhFE70cGYKiA93f2EjPYzcts2+PHHyCWUWbNg3bri69ev7xJHaGrRAvbee8+pYcOq8R9fQ510EkyfDldcAUOHuiknxyWOCy+EVq3gpZfgqafcL/7KTBZQdT466enw3HPQqJErZWzcCCNGuIL88uWuZHHHHVWj0G4lDFNxW7a4JFKyquuHH9x/xMaNkbfLyIicSPbeG/bZp/jzrCz3n2eSYtkymDjRVZ98/bWbd9RRMH8+HHQQfPKJvT2lUYXbboN//Qv69oWxY93jO+90/ypt2yYnLquSMqllxw5Yu9ZV6JacVq/ec97OnZH307TpnokkWqJp3Ljq/AStYhYvhhdfdNNPP8GMGbHbOExx993n2jJOOw0WLID993fVf8liCcNUXaqweXPkRBIpwWzYEHk/6emuVNKokav6atDATeV9bD+fIyoqqhpVKalm1Cj405/cx338eNfonSzWhmGqLhFXOmjcGA48sPT18/NdG0q0BLNli+u+8+uvrh0m9HjLFvjtt+Bx1alTPJEESTIZGbununVj/w09rmLfvlUs3JQxaJArML/8Mpx9drKjCc5KGKbmKix0SSM8qUR7HGtZ+OPt2ysWU3p66UklyLK6dV2SKzlFmx9rndq1rXqvGrMShjFBpKW50kDDhvHbZ0FB8eSxfbtrwyn5ONrfIOts2RJ7nUQoS/JJT989lXweaSptnfLsI/x5WlpiXpMayBKGMfFUuzY0aeKmZFB1nQbCpx079pxXnnWCrLdtm2uDys93z/Pzo087d7p4E61WrciJJBGPy5rogq6bIknPEoYx1YnI7iqpqqCwMHZSCZJ4oq0Tmhe+LMjjHTtcCTHI+tF69MWbSOwE06IFTJuW8DAsYRhjkictzU0ZGcmOpHxUIye9IEmuvOtHWjee1aoxWMIwxpjyEnHVkLVrQ716yY4m4axTnDHGmEASmjBE5BQRWSQiS0RkSITldUXkRb/8KxFpF7ZsqJ+/SEROTmScxhhjSpewhCEiacCjwKlAR6CfiHQssdqVwC+quj/wAHCv37Yj0BfoBJwCPOb3Z4wxJkkSWcLIAZao6lJV3QlMAPqUWKcP8Kx//DJwgoiInz9BVXeo6g/AEr8/Y4wxSZLIhNESWBH2PM/Pi7iOqhYAm4DmAbc1xhhTiap8o7eIDBKRXBHJXbt2bbLDMcaYaiuRCWMl0DrseSs/L+I6IlIbaAysD7gtAKo6SlWzVTU7KysrTqEbY4wpKZEJYwZwgIi0F5E6uEbsSSXWmQRc5h+fD3zob0o+Cejre1G1Bw4ApicwVmOMMaVI2IV7qlogItcCU4A0YIyqfiMidwO5qjoJeAp4TkSWABtwSQW/3kRgAVAADFbVwtKOOXPmzHUisjzGKpnAuhjLqxo7n9RWnc6nOp0L2PmEC3yvv2o1vHlpRCQ36DC+VYGdT2qrTudTnc4F7HzKq8o3ehtjjKkcljCMMcYEUtMSxqhkBxBndj6prTqdT3U6F7DzKZca1YZhjDGm/GpaCcMYY0w51ZiEUdrIuZUcyxgRWSMi88PmNROR90Rksf/b1M8XEXnYxz1XRLqHbXOZX3+xiFwWNr+HiMzz2zzsx+eKeow4nE9rEflIRBaIyDcickNVPicRyRCR6SIyx5/PXX5+ez+q8hI/ynIdP7/Moy5H+zxGO0YczilNRL4Wkbeqwbks85+F2SKS6+dVyc+a328TEXlZRL4VkYUicmTKno+qVvsJdx3I98B+QB1gDtAxifEcA3QH5ofNuw8Y4h8PAe71j08DJgMCHAF85ec3A5b6v03946Z+2XS/rvhtT411jDicz75Ad/+4IfAdboTiKnlO/hgN/ON04Ct/7IlAXz9/JHC1f3wNMNI/7gu86B939J+1ukB7/xlMi/V5jHaMOJzTzcB44K1Yx6ki57IMyCwxr0p+1vy+ngWu8o/rAE1S9XyS8oVZ2RNwJDAl7PlQYGiSY2pH8YSxCNjXP94XWOQfPwH0K7ke0A94Imz+E37evsC3YfN3rRftGAk4tzeAk6rDOQF7AbOAw3EXRtUu+ZnCXZx6pH9c268nJT9nofWifR79NhGPUcFzaAV8ABwPvBXrOKl+Ln5fy9gzYVTJzxpuOKQf8O3JqX4+NaVKqiqMfruPqq7yj38G9vGPo8Uea35ehPmxjhE3vgqjG+5XeZU9J1+FMxtYA7yH+xW9Ud2oyiVjKOuoy9HmN49xjIp4EPgLUOSfxzpOqp8LgALvishMERnk51XVz1p7YC3wtK8yHC0i9VP1fGpKwqhS1KX8hHZfS8QxRKQB8Apwo6puTvTxSornMVS1UFW74n6d5wAHxWO/lU1EzgDWqOrMZMcSRz1VtTvu5myDReSY8IVV7LNWG1c9/biqdgO24qqHEnGsqIIeo6YkjMCj3ybRahHZF8D/XePnR4s91vxWEebHOkaFiUg6LlmMU9VXq8M5AajqRuAjXJVKE3GjKpeMoayjLkebvz7GMcrrKOAsEVmGu4nZ8cBDVfRcAFDVlf7vGuA1XEKvqp+1PCBPVb/yz1/GJZCUPJ+akjCCjJybbOEj916GawcIzb/U9444Atjki5FTgN4i0tT3buiNqyNeBWwWkSN8b4hLS+wr0jEqxB/nKWChqg6v6uckIlki0sQ/rodrj1mISxznRzmfUAxBRl2O+Hn020Q7Rrmo6lBVbaWq7fxxPlTVS6riuQCISH0RaRh6jPuMzKeKftZU9WdghYj83s86ATfoamqeT0UbbarKhOtd8B2uLvq2JMfyArAKyMf9wrgSV+f7AbAYeB9o5tcV3L3RvwfmAdlh+7kCd/vaJcDAsPnZuH+i74ER7L5AM+Ix4nA+PXHF2bnAbD+dVlXPCTgE+Nqfz3zgb37+frgvySXAS0BdPz/DP1/il+8Xtq/bfMyL8L1TYn0eox0jTu/TcezuJVUlz8Xvc46fvgkdr6p+1vx+uwK5/vP2Oq6XU0qej13pbYwxJpCaUiVljDGmgixhGGOMCcQShjHGmEAsYRhjjAnEEoYxxphALGGYSiMiH4tIwu87LCLXixv1c1yJ+V1F5LRy7O93IvJygPXeDl2/UR2ISDsJG1HZmNqlr2JM8olIbd09LlFprgFOVNW8EvO74vqkv12W/avqT+y+AC0qVS1zMjKmKrEShinG/6pcKCJPirsXxLv+audiJQQRyfTDTSAil4vI635M/WUicq2I3OwHU/tSRJqFHWKAuPsYzBeRHL99fXH3CJnut+kTtt9JIvIh7gKjkrHe7PczX0Ru9PNG4i7umiwiN4WtWwe4G7jIH/8iEblTRJ4Tkc+A5/y5fyIis/z0h7DXZH5YTK+KyDvi7iNwX9gxlvnXJdZreJi4+xjMFpF/R/sFLyL/JyIz/Lp3ldg2w79m34hIZxFpICIf+Jjnhb1+7cTdY+EZEflORMaJyIki8pmPPfT6h16HL/z8/4kQT5qPNxTTH/38fUVkWth7enSEbe8Rd6+UuSJyv5+XJSKv+P3NEJGjAnwWIr7uphLF6ypSm6rHhBt2vQDo6p9PBPr7xx/jrywFMoFl/vHluKtLGwJZuBFO/+SXPYAbjDC0/ZP+8TH44d2Bf4YdownuquH6fr95RLgCFeiBu9K1PtAAd9VvN79sGSWGvw6Lc0TY8zuBmUA9/3wvIMM/PgDIDXtN5oftYylujKUMYDnQOvy4pbyG89k9fPg9hA1xHxZXb9w9mgX3o+4t4Bi/7O/A/birfYf6ebWBRmHvyxK/bSiOLn4/M4Exflkf4PWw12EOUM9vvwL4XYnzHgTc7h/XxV2Z3B74X3ZfbZ0GNCxxLs1xV4aHLhJu4v+Oxw0iCNAGN6wMxP4sRHzdbaq8yaqkTCQ/qOps/3gm7oujNB+p6hZgi4hsAt708+fhhtoIeQFAVaeJSCNxdf69cQPk/dmvk4H7EgF4T1U3RDheT+A1Vd0KICKvAkfjhvQoi0mqus0/TgdGiEhXoBA4MMo2H6jqJn/cBUBbig8tDRFeQ3+uDVX1Cz9/PHBGhP339lPoXBrgEtg0XClpBrAduN4vF+Cf4kZtLcINXx0aqvoHVZ3nY/3Gx64iMo/i7+sb/nXYJiIf4Qb0mx22vDdwiIiEquYa+5hmAGPEDT75etg5h2zysT4l7m5/b/n5JwIdxd38DaCRuNGOY30WgrzuJoEsYZhIdoQ9LsT98gT3azVUjZkRY5uisOdFFP+clRyLRnFfeOep6qLwBSJyOG6450QK3/9NwGrgUNx5bo+yTcnXJ9L/UbTXMAgB/qWqT0RY1hyXQNJx78FW4BJcya6HquaLqyoMvT8VeV9KxnSdqk7ZI1iXqE4HnhGR4ao6dtdOVAt81dcJuHaga3Ej5tYCjlDV7SX2FeuzEOR1NwlkbRimLJbhqoIgQCNwFBcBiEhP3Eibm3AjbV7nvywQkW4B9vMJcLaI7CVu1NJz/LxYtuCqzaJpDKxS1SJgAK6KJW7UDZW+xX/5gRvZNZIpwBX+Fzci0lJE9vbLngD+CowD7g2Le41PFr1wv7zLqo9vG2mOG6RwRoSYrvYlCUTkQN/e0BZYrapPAqNxQ3Pv4s+hsaq+jUvIh/pF7wLXha3XNew4Zf0smEpiGdqUxf3ARHF3OftvOfexXUS+xv1CvsLPG4a7K9xcEamFu2VlpKqaXVR1log8gxsNFWC0qpZWHfURMETcnfT+FWH5Y8ArInIp8A6JKd1cCTwpIkXAVFyVTTGq+q6IHAx84b83fwX6i8gpQL6qjheRNOBzETkelzze9NVMucC35YhrLu71yQSGqepP4u6eGDIaV4U1y3+ZrwXOxiWX/xORfB/npSX22xB4Q0QycKWUm/3864FHRWQu7ntoGvAnyvFZMJXHRqs1phKJSANV/dU/HoK7p/INSY7pTuBXVb0/mXGY1GclDGMq1+kiMhT3v7cc1/vHmCrBShjGGGMCsUZvY4wxgVjCMMYYE4glDGOMMYFYwjDGGBOIJQxjjDGBWMIwxhgTyP8DEHcT02LQmsIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.plot(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get nodes values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.aiworkbox.com/lessons/examine-mnist-dataset-from-pytorch-torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = np.asarray(mnist_trainset[0][0]) # image\n",
    "y_train_0 = mnist_trainset[0][1] # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_loader_for_MI = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=False)\n",
    "\n",
    "# test\n",
    "test_loader_for_MI = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_for_MI():\n",
    "    network.eval()\n",
    "    \n",
    "    list = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(train_loader_for_MI):\n",
    "            result = network(data)\n",
    "            list.append(result)\n",
    "            \n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_for_MI():\n",
    "    network.eval()\n",
    "    \n",
    "    list = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader_for_MI):            \n",
    "            result = network(data)\n",
    "            list.append(result)\n",
    "            \n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uchiumi/.local/lib/python3.5/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "list = train_data_for_MI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv2_output', 'fc2_output', 'output_softmax', 'fc1_output', 'input_image', 'conv1_output'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_image torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 10, 12, 12])\n",
      "torch.Size([1, 20, 4, 4])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(\"input_image\", list[0][\"input_image\"].shape)\n",
    "print(list[0][\"conv1_output\"].shape)\n",
    "print(list[0][\"conv2_output\"].shape)\n",
    "print(list[0][\"fc1_output\"].shape)\n",
    "print(list[0][\"fc2_output\"].shape)\n",
    "print(list[0][\"output_softmax\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordata_input_image = []\n",
    "tensordata_conv1_output = []\n",
    "tensordata_conv2_output = []\n",
    "tensordata_fc1_output = []\n",
    "tensordata_fc2_output = []\n",
    "tensordata_output_softmax = []\n",
    "\n",
    "for i in range(len(train_loader_for_MI)):\n",
    "    tensordata_input_image.append(list[i][\"input_image\"].data.numpy().flatten())\n",
    "    tensordata_conv1_output.append(list[i][\"conv1_output\"].data.numpy().flatten())\n",
    "    tensordata_conv2_output.append(list[i][\"conv2_output\"].data.numpy().flatten())\n",
    "    tensordata_fc1_output.append(list[i][\"fc1_output\"].data.numpy().flatten())\n",
    "    tensordata_fc1_output.append(list[i][\"fc2_output\"].data.numpy().flatten())\n",
    "    tensordata_output_softmax.append(list[i][\"output_softmax\"].data.numpy().flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordata_input_image = np.array(tensordata_input_image)\n",
    "tensordata_conv1_output = np.array(tensordata_conv1_output)\n",
    "tensordata_conv2_output = np.array(tensordata_conv2_output)\n",
    "tensordata_fc1_output = np.array(tensordata_fc1_output)\n",
    "tensordata_fc2_output = np.array(tensordata_fc2_output)\n",
    "tensordata_output_softmax = np.array(tensordata_output_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MINE (試作ver.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tensordata_conv1_output\n",
    "y = tensordata_conv2_output\n",
    "z = np.concatenate([x, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1440)\n",
      "(60000, 320)\n",
      "(60000, 1760)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch(x, y, sample_size, batch_size=int(1e2), sample_mode='joint'):\n",
    "    if sample_mode == 'joint':\n",
    "        index_1 = np.random.choice(range(sample_size), size=batch_size, replace=False)\n",
    "        z = np.concatenate([x, y], axis=1)\n",
    "        batch = z[index_1]\n",
    "    elif sample_mode == 'marginal':\n",
    "        index_1 = np.random.choice(range(sample_size), size=batch_size, replace=False)\n",
    "        index_2 = np.random.choice(range(sample_size), size=batch_size, replace=False)\n",
    "        batch = np.concatenate([x[index_1], y[index_2]], axis=1)\n",
    "        \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1760)\n",
      "(1000, 1760)\n"
     ]
    }
   ],
   "source": [
    "# joint & marginal sample\n",
    "joint_data = sample_batch(x, y, x.shape[0], batch_size=1000, sample_mode='joint')\n",
    "marginal_data = sample_batch(x, y, x.shape[0], batch_size=1000,sample_mode='marginal')\n",
    "\n",
    "print(joint_data.shape)\n",
    "print(marginal_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticNet(nn.Module):\n",
    "    def __init__(self, xdim=1, ydim=1, hidden_size=10000):\n",
    "        super().__init__()\n",
    "        self.xdim = xdim\n",
    "        self.ydim = ydim\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.xdim+self.ydim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "        nn.init.normal_(self.fc1.weight, std=0.02)\n",
    "        nn.init.constant_(self.fc1.bias, 0)\n",
    "        nn.init.normal_(self.fc2.weight, std=0.02)\n",
    "        nn.init.constant_(self.fc2.bias, 0)\n",
    "        nn.init.normal_(self.fc3.weight, std=0.02)\n",
    "        nn.init.constant_(self.fc3.bias, 0)\n",
    "        nn.init.normal_(self.fc4.weight, std=0.02)\n",
    "        nn.init.constant_(self.fc4.bias, 0)\n",
    "        nn.init.normal_(self.fc5.weight, std=0.02)\n",
    "        nn.init.constant_(self.fc5.bias, 0)\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        output = F.relu(self.fc1(input_))\n",
    "        output = F.dropout(output, p=0.2, training=True)\n",
    "        output = F.relu(self.fc2(output))\n",
    "        output = F.dropout(output, p=0.2, training=True)\n",
    "        output = F.relu(self.fc3(output))\n",
    "        output = F.dropout(output, p=0.2, training=True)\n",
    "        output = F.relu(self.fc4(output))\n",
    "        output = F.dropout(output, p=0.2, training=True)\n",
    "        output = self.fc5(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MI_LowerBound(joint, marginal, net):\n",
    "    t = net(joint)\n",
    "    et = torch.exp(net(marginal))\n",
    "    mi_lb = torch.mean(t) - torch.log(torch.mean(et)) # Lower bound for MI\n",
    "    return mi_lb, t, et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(joint_batch, marginal_batch, net, optimizer, ma_et, ma_rate=0.01):\n",
    "    # batch is a tuple of (joint, marginal)\n",
    "    joint_batch = torch.autograd.Variable(torch.FloatTensor(joint_batch)).cuda()\n",
    "    marginal_batch = torch.autograd.Variable(torch.FloatTensor(marginal_batch)).cuda()\n",
    "    \n",
    "    mi_lb , t, et = calc_MI_LowerBound(joint_batch, marginal_batch, net)\n",
    "    \n",
    "    # unbiasing use moving average\n",
    "    ma_et = (1 - ma_rate) * ma_et + ma_rate * torch.mean(et)\n",
    "    loss = -1 * (torch.mean(t) - (1 / ma_et.mean()).detach() * torch.mean(et)) # original loss function\n",
    "    # use biased estimator\n",
    "    # loss = - mi_lb\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    autograd.backward(loss)\n",
    "    optimizer.step()\n",
    "    \n",
    "    return mi_lb, ma_et, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, net, optimizer, batch_size=1000, nb_epoch=int(5e+4), log_freq=int(5e+2)):\n",
    "\n",
    "    mi_lower_bounds = []\n",
    "    losses = []\n",
    "    # moving average of exp(T)\n",
    "    ma_et = 1.\n",
    "    \n",
    "    for i in range(nb_epoch):\n",
    "        if x.shape[0] != y.shape[0]: \n",
    "            print(\"shape error.\")\n",
    "            break\n",
    "            \n",
    "        sample_size = x.shape[0]\n",
    "        joint_batch = sample_batch(x, y, sample_size, batch_size=batch_size, sample_mode='joint')\n",
    "        marginal_batch = sample_batch(x, y, sample_size, batch_size=batch_size, sample_mode='marginal')\n",
    "        \n",
    "        mi_lb, ma_et, loss = update(joint_batch, marginal_batch, net, optimizer, ma_et)\n",
    "        mi_lower_bounds.append(mi_lb.detach().cpu().numpy())\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if (i + 1) % (log_freq) == 0:\n",
    "            print('epoch: {:>6} \\t MI lower bounds: {:2.4f} \\t Loss of MINE: {:2.4f}'.format(i+1, mi_lower_bounds[-1], losses[-1]))\n",
    "            \n",
    "    return mi_lower_bounds, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving average\n",
    "def ma(array, window_size=100):\n",
    "    return [np.mean(array[i : i + window_size]) for i in range(0, len(array) - window_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    500 \t MI lower bounds: 6.9652 \t Loss of MINE: -2.8194\n",
      "epoch:   1000 \t MI lower bounds: 4.6877 \t Loss of MINE: -2.6997\n",
      "epoch:   1500 \t MI lower bounds: 1.4051 \t Loss of MINE: 0.5222\n",
      "epoch:   2000 \t MI lower bounds: 6.8507 \t Loss of MINE: -2.7026\n",
      "epoch:   2500 \t MI lower bounds: 8.3592 \t Loss of MINE: -4.3389\n",
      "epoch:   3000 \t MI lower bounds: 3.9325 \t Loss of MINE: -0.5678\n",
      "epoch:   3500 \t MI lower bounds: 6.8348 \t Loss of MINE: -2.6565\n",
      "epoch:   4000 \t MI lower bounds: 7.1630 \t Loss of MINE: -2.4320\n",
      "epoch:   4500 \t MI lower bounds: 6.1829 \t Loss of MINE: -1.2273\n",
      "epoch:   5000 \t MI lower bounds: 2.9296 \t Loss of MINE: 2.3008\n",
      "epoch:   5500 \t MI lower bounds: 6.6761 \t Loss of MINE: -0.8939\n",
      "epoch:   6000 \t MI lower bounds: 8.8243 \t Loss of MINE: -2.2747\n",
      "epoch:   6500 \t MI lower bounds: 6.1483 \t Loss of MINE: -0.3390\n",
      "epoch:   7000 \t MI lower bounds: 7.3269 \t Loss of MINE: -1.0052\n",
      "epoch:   7500 \t MI lower bounds: 6.8829 \t Loss of MINE: -0.4273\n",
      "epoch:   8000 \t MI lower bounds: 4.4865 \t Loss of MINE: 6.8810\n",
      "epoch:   8500 \t MI lower bounds: 6.6370 \t Loss of MINE: 0.0076\n",
      "epoch:   9000 \t MI lower bounds: 6.4016 \t Loss of MINE: -0.0908\n",
      "epoch:   9500 \t MI lower bounds: 8.5994 \t Loss of MINE: -1.4639\n",
      "epoch:  10000 \t MI lower bounds: 8.9583 \t Loss of MINE: -1.5339\n",
      "epoch:  10500 \t MI lower bounds: 6.6028 \t Loss of MINE: 1.7463\n",
      "epoch:  11000 \t MI lower bounds: 1.9494 \t Loss of MINE: 4.0995\n",
      "epoch:  11500 \t MI lower bounds: 7.7331 \t Loss of MINE: -0.8556\n",
      "epoch:  12000 \t MI lower bounds: 4.8869 \t Loss of MINE: 1.7915\n",
      "epoch:  12500 \t MI lower bounds: 9.0686 \t Loss of MINE: -0.5515\n",
      "epoch:  13000 \t MI lower bounds: 10.9982 \t Loss of MINE: -0.4834\n",
      "epoch:  13500 \t MI lower bounds: 8.4208 \t Loss of MINE: 1.7406\n",
      "epoch:  14000 \t MI lower bounds: 5.5103 \t Loss of MINE: 2.2856\n",
      "epoch:  14500 \t MI lower bounds: 7.0521 \t Loss of MINE: 2.7638\n",
      "epoch:  15000 \t MI lower bounds: 3.6181 \t Loss of MINE: 4.2339\n",
      "epoch:  15500 \t MI lower bounds: 8.6612 \t Loss of MINE: 0.7005\n",
      "epoch:  16000 \t MI lower bounds: 7.9525 \t Loss of MINE: 0.3414\n",
      "epoch:  16500 \t MI lower bounds: 7.3335 \t Loss of MINE: 4.6880\n",
      "epoch:  17000 \t MI lower bounds: 6.4971 \t Loss of MINE: 3.1546\n",
      "epoch:  17500 \t MI lower bounds: 11.0706 \t Loss of MINE: -0.3850\n",
      "epoch:  18000 \t MI lower bounds: 7.7975 \t Loss of MINE: 1.3654\n",
      "epoch:  18500 \t MI lower bounds: 9.3895 \t Loss of MINE: 0.4024\n",
      "epoch:  19000 \t MI lower bounds: 9.4252 \t Loss of MINE: 1.5326\n",
      "epoch:  19500 \t MI lower bounds: 6.8192 \t Loss of MINE: 0.9216\n",
      "epoch:  20000 \t MI lower bounds: 9.5511 \t Loss of MINE: -0.2135\n",
      "epoch:  20500 \t MI lower bounds: 7.1796 \t Loss of MINE: 1.4890\n",
      "epoch:  21000 \t MI lower bounds: 5.6250 \t Loss of MINE: 1.5722\n",
      "epoch:  21500 \t MI lower bounds: 7.2546 \t Loss of MINE: 0.7059\n",
      "epoch:  22000 \t MI lower bounds: 4.7141 \t Loss of MINE: 3.8900\n",
      "epoch:  22500 \t MI lower bounds: 9.5119 \t Loss of MINE: 1.8742\n",
      "epoch:  23000 \t MI lower bounds: 4.9641 \t Loss of MINE: 5.3246\n",
      "epoch:  23500 \t MI lower bounds: 7.4013 \t Loss of MINE: -0.5725\n",
      "epoch:  24000 \t MI lower bounds: 7.3540 \t Loss of MINE: -0.1362\n",
      "epoch:  24500 \t MI lower bounds: 3.8571 \t Loss of MINE: 3.8890\n"
     ]
    }
   ],
   "source": [
    "net = StochasticNet(xdim=x.shape[1], ydim=y.shape[1]).cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "\n",
    "mi_lower_bounds, losses = train(x, y, net, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MI lower boundsのプロット\n",
    "\n",
    "mi_lower_bound_ma = ma(mi_lower_bounds, window_size=200)\n",
    "\n",
    "plt.title(\"Moving Average of MI(X, Y) \\n  (window_size=200)\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MA of MI(X, Y)\")\n",
    "plt.plot(range(len(mi_lower_bound_ma)), mi_lower_bound_ma)\n",
    "plt.show()\n",
    "\n",
    "print(\"Final value of MI: \", mi_lower_bound_ma[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MI lower boundsのプロット\n",
    "\n",
    "mi_lower_bound_ma = ma(mi_lower_bounds, window_size=200)\n",
    "\n",
    "plt.title(\"Moving Average of MI(X, Y) \\n  (window_size=200)\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MA of MI(X, Y)\")\n",
    "plt.plot(range(len(mi_lower_bound_ma)), mi_lower_bound_ma)\n",
    "plt.show()\n",
    "\n",
    "print(\"Final value of MI: \", mi_lower_bound_ma[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lossのプロット\n",
    "\n",
    "plt.title(\"Loss of MINE \\n  (window_size=200)\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MA of MI(X, Y)\")\n",
    "plt.plot(range(len(losses)), losses)\n",
    "plt.show()\n",
    "\n",
    "print(\"Final value of Loss: \", losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
