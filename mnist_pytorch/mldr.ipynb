{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Density Ratio Estimation for MI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paper: http://proceedings.mlr.press/v4/suzuki08a/suzuki08a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Info\n",
      "=========\n",
      "- use_cuda:  True\n",
      "- Path:  /home/uchiumi/JNNS2019/mnist_pytorch\n",
      "- PyTorch 1.0.1.post2\n",
      "- Python:  3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Setting Info\")\n",
    "print(\"=========\")\n",
    "print(\"- use_cuda: \", use_cuda)\n",
    "print(\"- Path: \", os.getcwd())\n",
    "print(\"- PyTorch\", torch.__version__)\n",
    "print(\"- Python: \", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buildiing Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer_values={}\n",
    "        layer_values[\"input_image\"] = x\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        layer_values[\"conv1_output\"] = x\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        layer_values[\"conv2_output\"] = x\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        layer_values[\"fc1_output\"] = x\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        layer_values[\"fc2_output\"] = x\n",
    "        x = F.log_softmax(x)\n",
    "        layer_values[\"output_softmax\"] = x\n",
    "        \n",
    "        return layer_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model reload\n",
    "model = Network()\n",
    "\n",
    "PRETRAINED_MODEL_PATH = \"/home/uchiumi/JNNS2019/mnist_pytorch/train_log/model__2019-0422-1338.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(PRETRAINED_MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf.) https://www.aiworkbox.com/lessons/examine-mnist-dataset-from-pytorch-torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "mnist_testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0 = np.asarray(mnist_trainset[0][0]) # image\n",
    "y_train_0 = mnist_trainset[0][1] # label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_loader_for_MINE = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_loader_for_MINE = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get layer values (the state of each nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_with_train_data(model):\n",
    "    model.eval()\n",
    "    list = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(train_loader_for_MINE):\n",
    "            result = model(data)\n",
    "            list.append(result)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_with_test_data(model):\n",
    "    model.eval()\n",
    "    list = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader_for_MINE):            \n",
    "            result = model(data)\n",
    "            list.append(result)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uchiumi/.local/lib/python3.5/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "list = get_nodes_with_train_data(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv2_output', 'fc2_output', 'output_softmax', 'fc1_output', 'input_image', 'conv1_output'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_image torch.Size([1, 1, 28, 28])\n",
      "torch.Size([1, 10, 12, 12])\n",
      "torch.Size([1, 20, 4, 4])\n",
      "torch.Size([1, 50])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(\"input_image\", list[0][\"input_image\"].shape)\n",
    "print(list[0][\"conv1_output\"].shape)\n",
    "print(list[0][\"conv2_output\"].shape)\n",
    "print(list[0][\"fc1_output\"].shape)\n",
    "print(list[0][\"fc2_output\"].shape)\n",
    "print(list[0][\"output_softmax\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordata_input_image = []\n",
    "tensordata_conv1_output = []\n",
    "tensordata_conv2_output = []\n",
    "tensordata_fc1_output = []\n",
    "tensordata_fc2_output = []\n",
    "tensordata_output_softmax = []\n",
    "\n",
    "for i in range(len(train_loader_for_MINE)):\n",
    "    tensordata_input_image.append(list[i][\"input_image\"].data.numpy().flatten())\n",
    "    tensordata_conv1_output.append(list[i][\"conv1_output\"].data.numpy().flatten())\n",
    "    tensordata_conv2_output.append(list[i][\"conv2_output\"].data.numpy().flatten())\n",
    "    tensordata_fc1_output.append(list[i][\"fc1_output\"].data.numpy().flatten())\n",
    "    tensordata_fc1_output.append(list[i][\"fc2_output\"].data.numpy().flatten())\n",
    "    tensordata_output_softmax.append(list[i][\"output_softmax\"].data.numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordata_input_image = np.array(tensordata_input_image)\n",
    "tensordata_conv1_output = np.array(tensordata_conv1_output)\n",
    "tensordata_conv2_output = np.array(tensordata_conv2_output)\n",
    "tensordata_fc1_output = np.array(tensordata_fc1_output)\n",
    "tensordata_fc2_output = np.array(tensordata_fc2_output)\n",
    "tensordata_output_softmax = np.array(tensordata_output_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Density Ratio Estimation for MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tensordata_conv1_output\n",
    "y = tensordata_conv2_output\n",
    "z = np.concatenate([x, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1440)\n",
      "(60000, 320)\n",
      "(60000, 1760)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFkernel():\n",
    "    def __init__(self, sigma=0.5):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def __call__(self, x, y):\n",
    "        if x.shape[0] != y.shape[0]: \n",
    "            raise Exception(\"please arrange the shape of input arrray.\")\n",
    "            \n",
    "        self.sample_space_dim = x.shape[0]\n",
    "        return np.exp(-1 * ( np.sum((x - y)**2 ) / 2 * self.sigma**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.481823524646916e-05"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = RBFkernel(sigma=0.5)\n",
    "kernel(np.array([1, 2, 3]), np.array([6, 7, 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensityRatioEstimation():\n",
    "    def __init__(self, x, y, kernel):\n",
    "        if x.shape[0] != y.shape[0]:\n",
    "            raise Exception(\"please arrange the shape of input arrray x and y.\")\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.kernel = kernel\n",
    "        self.sample_size = x.shape[0]\n",
    "    \n",
    "    def update(self):\n",
    "        pass\n",
    "    \n",
    "    def fit_alpha(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
